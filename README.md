# Arabic Sign Language Recognition Project

A deep learning project for recognizing Arabic Sign Language (ArSL) gestures using computer vision techniques.

## ğŸ¯ Project Overview
 Huawei Cloud Integration Summary
ğŸŒŸ Services Integrated:
Object Storage Service (OBS) - For dataset and model storage
ModelArts - For distributed training and model management
API Gateway - For REST API deployment
Cloud Eye - For monitoring and alerting
Elastic Cloud Server (ECS) - For scalable compute
ğŸ“ New Files Created:
File	Purpose
huawei_cloud_config.yaml	Cloud configuration settings
huawei_storage.py	OBS integration for data storage
huawei_modelarts.py	ModelArts training management
train_arsl.py	Cloud-optimized training script
inference_service.py	Real-time inference service
api_deployment.py	API Gateway deployment
setup_huawei_cloud.py	Complete automated setup
HUAWEI_CLOUD_INTEGRATION.md	Comprehensive documentation
ğŸš€ Key Features:
âœ… Automated Dataset Upload to OBS with progress tracking
âœ… Distributed Training on GPU instances with ModelArts
âœ… Real-time Inference with REST API endpoints
âœ… Auto-scaling and load balancing capabilities
âœ… Monitoring & Alerting with Cloud Eye integration
âœ… Security with IAM roles and encryption
âœ… Cost Optimization recommendations

ğŸ› ï¸ Quick Start Commands:
# 1. Set up environment variables
$env:HUAWEI_ACCESS_KEY_ID = "your_access_key"
$env:HUAWEI_SECRET_ACCESS_KEY = "your_secret_key"
$env:HUAWEI_PROJECT_ID = "your_project_id"

# 2. Install cloud dependencies
pip install -r requirements.txt

# 3. Run complete setup
python scripts\setup_huawei_cloud.py --upload-data --start-training
This project implements a CNN-based approach to classify Arabic sign language gestures representing the 32 letters of the Arabic alphabet. The dataset contains over 108,000 images across 32 classes.

## ğŸ“Š Dataset Statistics

- **Total Images**: 108,098
- **Classes**: 32 (Arabic alphabet letters)
- **Image Format**: 64x64 grayscale images
- **Average per class**: ~3,378 images

## ğŸš€ Phase 1: Environment Setup âœ…

### Completed Tasks:
- âœ… Python 3.13+ environment with virtual environment
- âœ… All required packages installed (PyTorch, OpenCV, etc.)
- âœ… Dataset validation and analysis
- âœ… Data visualization and reporting
- âœ… Basic data pipeline testing
- âœ… Project structure setup

### Quick Start

1. **Activate the virtual environment:**
   ```powershell
   .\venv\Scripts\Activate.ps1
   ```

2. **Check Phase 1 status:**
   ```powershell
   python scripts\check_phase1_status.py
   ```

3. **Validate dataset:**
   ```powershell
   python scripts\validate_data.py
   ```

4. **Test data pipeline:**
   ```powershell
   python scripts\test_data_pipeline.py
   ```

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original image data (32 class folders)
â”‚   â”œâ”€â”€ processed/           # Processed data
â”‚   â”œâ”€â”€ analysis/            # Analysis results and visualizations
â”‚   â””â”€â”€ ArSL_Data_Labels.csv # Dataset labels
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/               # Data processing modules
â”‚   â”œâ”€â”€ models/             # Model definitions
â”‚   â””â”€â”€ utils/              # Utility functions
â”œâ”€â”€ scripts/                # Executable scripts
â”œâ”€â”€ config/                 # Configuration files
â”œâ”€â”€ models/                 # Saved model checkpoints
â”œâ”€â”€ logs/                   # Training logs
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â””â”€â”€ requirements.txt        # Python dependencies
```

## ğŸ”§ Requirements

### System Requirements:
- Windows 10/11
- Python 3.8+
- 8GB+ RAM (16GB recommended)
- 10GB+ free disk space

### Installed Packages:
- PyTorch 2.8.0
- OpenCV 4.12.0
- Pandas, NumPy, Matplotlib, Seaborn
- scikit-learn, tqdm, Pillow

## ğŸ“ˆ Results (Phase 1)

- **Environment Setup**: âœ… Complete
- **Dataset Validation**: âœ… 100% file integrity
- **Data Pipeline**: âœ… All tests passed
- **Project Structure**: âœ… Ready for development

## ğŸ”„ Next Steps (Phase 2)

1. Implement advanced data loaders with augmentation
2. Design and implement CNN architectures
3. Set up training pipeline with validation
4. Implement model evaluation and metrics
5. Create inference pipeline

## ğŸ“ Usage Examples

### Check Environment Status
```python
python scripts\check_phase1_status.py
```

### Validate Dataset
```python
python scripts\validate_data.py
```

### Test Data Loading
```python
python scripts\test_data_pipeline.py
```

## ğŸ” Analysis Results

View the generated analysis files:
- `data/analysis/class_distribution.png` - Class distribution visualization
- `data/analysis/validation_report.txt` - Detailed dataset report

## ğŸ‘¥ Contributing

This is a learning project for Arabic Sign Language recognition. Future improvements could include:
- Data augmentation techniques
- Advanced CNN architectures
- Transfer learning approaches
- Real-time inference capabilities

## ğŸ“„ License

Educational project - please respect the original dataset licensing terms.

---

**Status**: Phase 1 Complete âœ… | Ready for Phase 2 ğŸš€
